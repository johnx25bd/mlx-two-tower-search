{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Towers Model\n",
    "- based on word2vec embeddings from gensim\n",
    "- use a simple average of the word embeddings as the document embedding\n",
    "- use a simple feedforward neural network as the encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils.collate import collate\n",
    "from utils.load_data import load_word2vec\n",
    "from utils.preprocess_str import str_to_tokens\n",
    "from utils.checkpoint import save_checkpoint\n",
    "from core import DocumentDataset, TwoTowerModel, loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# print(inspect.getsource(collate).split('\\n', 1)[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import utils.checkpoint\n",
    "\n",
    "# importlib.reload(utils.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HYPERPARAMETERS\n",
    "RANDOM_SEED = 42\n",
    "FREEZE_EMBEDDINGS = True\n",
    "VERBOSE = True\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "MARGIN = 0.5\n",
    "LEARNING_RATE = 0.00001\n",
    "NUM_EPOCHS = 3\n",
    "MODEL_NAME = \"mlx-w2-two-tower-search\"\n",
    "PROJECTION_DIM = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "vocab,embeddings, word_to_idx = load_word2vec()\n",
    "embedding_layer = nn.Embedding.from_pretrained(embeddings, freeze=FREEZE_EMBEDDINGS)\n",
    "\n",
    "EMBEDDING_DIM = embeddings.shape[1]\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pd.read_parquet('../data/training.parquet')\n",
    "df_validation = pd.read_parquet('../data/validation.parquet')\n",
    "df_test = pd.read_parquet('../data/test.parquet')\n",
    "# df = df.sample(n=10000, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df, word_to_idx):\n",
    "    # Tokenize\n",
    "    df.loc[:, 'doc_rel_tokens'] = df['doc_relevant'].apply(lambda x: str_to_tokens(x, word_to_idx))\n",
    "    df.loc[:, 'doc_irr_tokens'] = df['doc_irrelevant'].apply(lambda x: str_to_tokens(x, word_to_idx))\n",
    "    df.loc[:, 'query_tokens'] = df['query'].apply(lambda x: str_to_tokens(x, word_to_idx))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "\n",
    "df = tokenize(df, word_to_idx)\n",
    "# df['doc_rel_tkn_length'] = df['doc_rel_tokens'].apply(len)\n",
    "# df['doc_irr_tkn_length'] = df['doc_irr_tokens'].apply(len)\n",
    "# df['query_tkn_length'] = df['query_tokens'].apply(len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=100000, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    df[['query_tkn_length']].hist(bins=100, layout=(2,1), figsize=(3, 3))\n",
    "    df[['doc_rel_tkn_length']].hist(bins=100, layout=(2,1), figsize=(10, 3))\n",
    "    df[['doc_irr_tkn_length']].hist(bins=100, layout=(2,1), figsize=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = DocumentDataset(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    i = 0\n",
    "    for docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask in dataloader:\n",
    "        print('Batch', i + 1)\n",
    "        print(\"Relevant Documents shape:\", docs_rel.shape)\n",
    "        print(\"Irrelevant Documents shape:\", docs_irr.shape)\n",
    "        print(\"Queries shape:\", queries.shape)\n",
    "        print(\"Relevant Document mask shape:\", docs_rel_mask.shape)\n",
    "        print(\"Irrelevant Document mask shape:\", docs_irr_mask.shape)\n",
    "        print(\"Query mask shape:\", query_mask.shape)\n",
    "\n",
    "        i += 1\n",
    "        if i > 0:\n",
    "            break  # Just print the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import core\n",
    "\n",
    "importlib.reload(core)\n",
    "from core import TwoTowerModel, DocumentDataset, loss_fn\n",
    "\n",
    "import utils.collate\n",
    "\n",
    "importlib.reload(utils.collate)\n",
    "from utils.collate import collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create model\n",
    "model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, projection_dim=PROJECTION_DIM, embedding_layer=embedding_layer, margin=MARGIN)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    model.eval()\n",
    "    dataiter = iter(dataloader)\n",
    "    docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask = next(dataiter)\n",
    "\n",
    "    print(\"docs_rel.shape:\", docs_rel.shape)\n",
    "    print(\"docs_irr.shape:\", docs_irr.shape)\n",
    "    print(\"queries.shape:\", queries.shape)\n",
    "    print(\"docs_rel_mask.shape:\", docs_rel_mask.shape)\n",
    "    print(\"docs_irr_mask.shape:\", docs_irr_mask.shape)\n",
    "    print(\"query_mask.shape:\", query_mask.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        similarity_rel = model(docs_rel, queries, doc_mask=docs_rel_mask, query_mask=query_mask)\n",
    "        similarity_irr = model(docs_irr, queries, doc_mask=docs_irr_mask, query_mask=query_mask)\n",
    "    similarity_rel, similarity_irr\n",
    "\n",
    "    loss = loss_fn(similarity_rel, similarity_irr, MARGIN)\n",
    "    print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_dim_sweep = [24, 48, 96, 192]\n",
    "margin_sweep = [0.1, 0.4, 0.7, 1.0]\n",
    "lr_sweep = [LEARNING_RATE * i for i in [0.0001, 0.001, 0.01, 0.1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import wandb\n",
    "\n",
    "# importlib.reload(wandb)\n",
    "# import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection_dim in projection_dim_sweep:\n",
    "    run_name = f\"avg_pooling_projection_dim_{projection_dim}_commit_3799989\"\n",
    "    model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, \n",
    "                          projection_dim=projection_dim, \n",
    "                          embedding_layer=embedding_layer, \n",
    "                          margin=MARGIN)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    wandb.init(project=MODEL_NAME, name=run_name)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1} of {NUM_EPOCHS}\")\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print(f\"Batch {batch_idx + 1} of {len(dataloader)}\")\n",
    "            docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask = batch\n",
    "\n",
    "            similarity_rel = model(docs_rel, queries, doc_mask=docs_rel_mask, query_mask=query_mask)\n",
    "            similarity_irr = model(docs_irr, queries, doc_mask=docs_irr_mask, query_mask=query_mask)\n",
    "\n",
    "            loss = loss_fn(similarity_rel, similarity_irr, MARGIN)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"loss\": loss.item()})\n",
    "        save_checkpoint(model, epoch, run_name)\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for margin in margin_sweep:\n",
    "    run_name = f\"avg_pooling_margin_{margin}_commit_3799989\"\n",
    "    model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, projection_dim=PROJECTION_DIM, embedding_layer=embedding_layer, margin=margin)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    wandb.init(project=MODEL_NAME, name=run_name)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1} of {NUM_EPOCHS}\")\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print(f\"Batch {batch_idx + 1} of {len(dataloader)}\")\n",
    "            docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask = batch\n",
    "\n",
    "            similarity_rel = model(docs_rel, queries, doc_mask=docs_rel_mask, query_mask=query_mask)\n",
    "            similarity_irr = model(docs_irr, queries, doc_mask=docs_irr_mask, query_mask=query_mask)\n",
    "\n",
    "            loss = loss_fn(similarity_rel, similarity_irr, MARGIN)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"loss\": loss.item()})\n",
    "        save_checkpoint(model, epoch, MODEL_NAME)\n",
    "        \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lr_sweep:\n",
    "    run_name = f\"avg_pooling_learning_rate_{lr}_commit_3799989\"\n",
    "    model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, projection_dim=PROJECTION_DIM, embedding_layer=embedding_layer, margin=MARGIN)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    wandb.init(project=MODEL_NAME, name=run_name)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('Learning Rate:', lr)\n",
    "        print(f\"Epoch {epoch + 1} of {NUM_EPOCHS}\")\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx % 5000 == 0:\n",
    "                print(f\"E{epoch + 1}: Batch {batch_idx + 1} of {len(dataloader)}\")\n",
    "            docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask = batch\n",
    "\n",
    "            similarity_rel = model(docs_rel, queries, doc_mask=docs_rel_mask, query_mask=query_mask)\n",
    "            similarity_irr = model(docs_irr, queries, doc_mask=docs_irr_mask, query_mask=query_mask)\n",
    "\n",
    "            loss = loss_fn(similarity_rel, similarity_irr, MARGIN)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"loss\": loss.item()})\n",
    "        save_checkpoint(model, epoch, run_name)\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, projection_dim=PROJECTION_DIM, embedding_layer=embedding_layer, margin=MARGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'./checkpoints/avg_pooling_learning_rate_1e-05_commit_3799989_20241024_170821_epoch_3_3799989.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, margin):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            docs_rel, docs_irr, queries, docs_rel_mask, docs_irr_mask, query_mask = batch\n",
    "            \n",
    "            similarity_rel = model(docs_rel, queries, doc_mask=docs_rel_mask, query_mask=query_mask)\n",
    "            similarity_irr = model(docs_irr, queries, doc_mask=docs_irr_mask, query_mask=query_mask)\n",
    "            \n",
    "            loss = loss_fn(similarity_rel, similarity_irr, margin)\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / total_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_validation_sample = tokenize(df_validation.sample(n=1000, random_state=RANDOM_SEED), word_to_idx).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset and dataloader\n",
    "validation_dataset = DocumentDataset(df_validation_sample)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, validation_dataloader, MARGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_doc = df_validation_sample.loc[0, 'doc_relevant']\n",
    "irr_doc = df_validation_sample.loc[0, 'doc_irrelevant']\n",
    "query = df_validation_sample.loc[0, 'query']\n",
    "\n",
    "rel_doc_tokens = torch.tensor(df_validation_sample.loc[0, 'doc_rel_tokens'])\n",
    "irr_doc_tokens = torch.tensor(df_validation_sample.loc[0, 'doc_irr_tokens'])\n",
    "query_tokens = torch.tensor(df_validation_sample.loc[0, 'query_tokens'])\n",
    "\n",
    "print(rel_doc_tokens.shape)\n",
    "print(irr_doc_tokens.shape)\n",
    "print(query_tokens.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    similarity_rel = model(rel_doc_tokens.unsqueeze(0), query_tokens.unsqueeze(0))\n",
    "    similarity_irr = model(irr_doc_tokens.unsqueeze(0), query_tokens.unsqueeze(0))\n",
    "\n",
    "similarity_rel, similarity_irr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the effects of climate change?\"\n",
    "documents = [\n",
    "    \"Climate change is causing rising sea levels and more frequent extreme weather events.\",\n",
    "    \"The Earth orbits around the Sun in an elliptical path.\",\n",
    "    \"Global warming is leading to the melting of polar ice caps and glaciers.\",\n",
    "    \"Photosynthesis is the process by which plants convert sunlight into energy.\",\n",
    "    \"Increased greenhouse gas emissions are a major contributor to global climate change.\",\n",
    "    \"The recipe for a classic Margherita pizza includes fresh mozzarella, tomatoes, and basil.\",\n",
    "    \"The history of the Roman Empire is marked by significant military conquests and cultural achievements.\",\n",
    "    \"Quantum mechanics explores the behavior of particles at the atomic and subatomic levels.\",\n",
    "    \"The rules of chess involve strategic movement of pieces like the knight, bishop, and rook.\",\n",
    "    \"The process of photosynthesis in plants involves converting carbon dioxide and water into glucose and oxygen using sunlight.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Tokenize and prepare the query\n",
    "    query_tokens = torch.tensor([str_to_tokens(query, word_to_idx)])\n",
    "    query_mask = (query_tokens != 0).float()\n",
    "\n",
    "    # Tokenize and prepare the documents\n",
    "    doc_tokens = [torch.tensor([str_to_tokens(doc, word_to_idx)]) for doc in documents]\n",
    "    doc_masks = [(doc != 0).float() for doc in doc_tokens]\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for doc, mask in zip(doc_tokens, doc_masks):\n",
    "        similarity = model(doc, query_tokens, doc_mask=mask, query_mask=query_mask)\n",
    "        similarities.append(similarity.item())\n",
    "\n",
    "    # Sort documents by similarity\n",
    "    ranked_docs = sorted(zip(documents, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_docs = pd.DataFrame(ranked_docs, columns=['Document', 'Similarity'])\n",
    "df_ranked_docs['Query'] = query\n",
    "df_ranked_docs = df_ranked_docs[['Query', 'Document', 'Similarity']]\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "styled_df = df_ranked_docs.style.set_table_styles(\n",
    "    {\n",
    "        'Query': [{'selector': '', 'props': [('width', '150px')]}],\n",
    "        'Document': [{'selector': '', 'props': [('width', '600px')]}]\n",
    "    }\n",
    ")\n",
    "\n",
    "styled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the document embeddings matrix\n",
    "- For each document, compute the projection\n",
    "- Store the document embeddings in a matrix\n",
    "- Store the document ids in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/training-with-tokens.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/training-with-tokens.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['query', 'doc_relevant', 'url_relevant']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need, we have the tokenized parquet file — run if you need to rebuild this\n",
    "# tqdm.pandas()\n",
    "# df['doc_rel_tokens'] = df.apply(lambda x: str_to_tokens(x['doc_relevant'], word_to_idx), axis=1)\n",
    "# df.to_parquet('../data/training_with_tokens.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_doc_projection(model, doc_tokens):\n",
    "#     doc_tensor = torch.tensor(df.loc[0, 'doc_rel_tokens']).unsqueeze(0)\n",
    "#     doc_mask = (doc_tensor != 0).float()\n",
    "#     doc_embeddings = model.embedding(doc_tensor)\n",
    "#     doc_encoding = doc_embeddings.mean(dim=1).unsqueeze(1)\n",
    "#     doc_projection = model.doc_project(doc_encoding).squeeze()\n",
    "#     return doc_projection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import core\n",
    "\n",
    "importlib.reload(core)\n",
    "from core import DocDataset, collate_docdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dataset = DocDataset(df, word_to_idx)\n",
    "doc_dataloader = DataLoader(doc_dataset, batch_size=32, shuffle=False, collate_fn=collate_docdataset)\n",
    "    # Shuffle MUST be set to false to preserve the order of the documents\n",
    "for tokens, mask, indices in doc_dataloader:\n",
    "    print(tokens.shape)\n",
    "    print(mask.shape)\n",
    "    print(indices.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "doc_projections = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_tokens, batch_mask, batch_indices in tqdm(doc_dataloader):\n",
    "\n",
    "        doc_encodings = model.doc_encode(batch_tokens, batch_mask)\n",
    "        batch_projections = model.doc_project(doc_encodings)\n",
    "\n",
    "        doc_projections.append(batch_projections)\n",
    "        doc_indices.append(batch_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_projections = torch.cat(doc_projections, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_projection_dim = doc_projections.shape[1] # same as PROJECTION_DIM\n",
    "num_docs = doc_projections.shape[0] # same as len(df), len(doc_indices)\n",
    "doc_embedding_matrix = nn.Embedding.from_pretrained(doc_projections, freeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(doc_embedding_matrix.weight.data, '../data/doc-embedding-matrix-64.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils.preprocess_str import str_to_tokens\n",
    "from utils.load_data import load_word2vec\n",
    "from core import TwoTowerModel\n",
    "\n",
    "vocab,embeddings, word_to_idx = load_word2vec()\n",
    "embedding_layer = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
    "\n",
    "EMBEDDING_DIM = embeddings.shape[1]\n",
    "PROJECTION_DIM = 64\n",
    "MARGIN = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_projections = torch.load('../data/doc-embedding-matrix-64.pth', weights_only=True)\n",
    "doc_projections_matrix = nn.Embedding.from_pretrained(doc_projections, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_projection(doc_id, doc_projections_matrix=doc_projections_matrix):\n",
    "    return doc_projections_matrix(torch.tensor(doc_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1573, -0.1160,  0.0340,  0.0244, -0.1314,  0.1808,  0.1675,  0.0514,\n",
       "         0.0780,  0.0397,  0.0029,  0.1056,  0.0607, -0.0872,  0.1253, -0.0288,\n",
       "        -0.2060,  0.0794,  0.0403, -0.1794, -0.1079,  0.1292,  0.0056,  0.0942,\n",
       "         0.2491, -0.0205, -0.1048, -0.2030,  0.0147, -0.0356, -0.0752,  0.0238,\n",
       "         0.0261,  0.0346,  0.0281,  0.0402,  0.0281, -0.0985, -0.1416,  0.1403,\n",
       "        -0.0901, -0.0294,  0.1185,  0.1044,  0.0388,  0.0470, -0.0932, -0.0366,\n",
       "         0.0066,  0.0458, -0.0994, -0.0824, -0.1157,  0.0107,  0.0670, -0.0250,\n",
       "         0.1338, -0.0573,  0.1258, -0.0362,  0.0197,  0.0346, -0.0270,  0.1348])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_doc_projection(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_projections_np = doc_projections_matrix.weight.data.numpy()\n",
    "dimension = doc_projections_np.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15728916, -0.11602148,  0.03402309,  0.0243528 , -0.13137114,\n",
       "        0.18077607,  0.16750537,  0.05138404,  0.07804341,  0.03973445,\n",
       "        0.00292916,  0.10556114,  0.06071091, -0.08719876,  0.12527376,\n",
       "       -0.02882197, -0.20598128,  0.07935658,  0.04032397, -0.17938608,\n",
       "       -0.10789324,  0.1292444 ,  0.00563716,  0.09421676,  0.24905732,\n",
       "       -0.02047169, -0.1047775 , -0.2030437 ,  0.01469753, -0.03559981,\n",
       "       -0.07521243,  0.0238389 ,  0.02609443,  0.03464166,  0.02805131,\n",
       "        0.04018955,  0.02807336, -0.09852565, -0.14158927,  0.14026608,\n",
       "       -0.0900612 , -0.02940441,  0.1184871 ,  0.10437067,  0.0388245 ,\n",
       "        0.04695689, -0.09324557, -0.03660403,  0.00662894,  0.04576072,\n",
       "       -0.09939746, -0.0824083 , -0.11573933,  0.01073795,  0.06702912,\n",
       "       -0.02503499,  0.13383216, -0.05731182,  0.12581532, -0.03617848,\n",
       "        0.01969791,  0.03459676, -0.02697205,  0.13477667], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_projections_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize vectors in batches\n",
    "def normalize_vectors(vectors, batch_size=10000):\n",
    "    normalized_vectors = np.copy(vectors)\n",
    "    for i in tqdm(range(0, len(normalized_vectors), batch_size)):\n",
    "        batch = normalized_vectors[i:i+batch_size]\n",
    "        faiss.normalize_L2(batch)\n",
    "        normalized_vectors[i:i+batch_size] = batch\n",
    "    return normalized_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 1619.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.2017562 , -0.14882177,  0.04364172,  0.03123755, -0.16851091,\n",
       "        0.23188305,  0.2148606 ,  0.06591076,  0.10010696,  0.05096773,\n",
       "        0.00375726,  0.1354042 ,  0.07787441, -0.11185062,  0.16068976,\n",
       "       -0.03697019, -0.264214  ,  0.10179138,  0.0517239 , -0.2301001 ,\n",
       "       -0.1383956 ,  0.16578293,  0.00723084,  0.12085267,  0.31946802,\n",
       "       -0.02625922, -0.13439901, -0.26044592,  0.01885265, -0.04566418,\n",
       "       -0.09647565,  0.03057837,  0.03347155,  0.04443516,  0.03598166,\n",
       "        0.05155149,  0.03600994, -0.12637971, -0.1816178 ,  0.17992052,\n",
       "       -0.1155223 , -0.0377173 ,  0.15198445,  0.13387717,  0.04980053,\n",
       "        0.06023201, -0.11960691, -0.04695231,  0.008503  ,  0.05869768,\n",
       "       -0.12749799, -0.10570585, -0.14845985,  0.01377366,  0.08597884,\n",
       "       -0.03211259,  0.17166768, -0.07351437,  0.1613844 , -0.04640646,\n",
       "        0.02526668,  0.04437757, -0.03459728,  0.17287922], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_doc_projections_np = normalize_vectors(doc_projections_np)\n",
    "normalized_doc_projections_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 677/677 [00:00<00:00, 2988.85it/s]\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "batch_size = 1000\n",
    "for i in tqdm(range(0, len(normalized_doc_projections_np), batch_size)):\n",
    "    batch = normalized_doc_projections_np[i:i+batch_size]\n",
    "    index.add(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, '../data/doc-index-64.faiss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from core import TwoTowerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/training-with-tokens.parquet')\n",
    "# index = faiss.read_index('../data/doc-index-64.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/gn_h4yzj0_9g3dttp_dn980r0000gn/T/ipykernel_153/3102827069.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./checkpoints/avg_pooling_learning_rate_1e-05_commit_3799989_20241024_170821_epoch_3_3799989.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TwoTowerModel(embedding_dim=EMBEDDING_DIM, projection_dim=PROJECTION_DIM, embedding_layer=embedding_layer, margin=MARGIN)\n",
    "model.load_state_dict(torch.load(f'./checkpoints/avg_pooling_learning_rate_1e-05_commit_3799989_20241024_170821_epoch_3_3799989.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get nearest neighbors\n",
    "def get_nearest_neighbors(query, model, df, k=5):\n",
    "    query_tokens = torch.tensor([str_to_tokens(query, word_to_idx)])\n",
    "    query_mask = (query_tokens != 0).float()\n",
    "    query_encoding = model.query_encode(query_tokens, query_mask)\n",
    "    query_projection = model.query_project(query_encoding)\n",
    "\n",
    "    query_vector = query_projection.detach().numpy()\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "\n",
    "    documents = df.loc[indices.squeeze()]['doc_relevant']\n",
    "    urls = df.loc[indices.squeeze()]['url_relevant']\n",
    "\n",
    "    return documents, urls, distances\n",
    "\n",
    "    # return df.loc[indices][['doc_relevant', 'url_relevant']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What is the capital of France?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, urls, distances = get_nearest_neighbors(q, model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8081      In Countries, States, and Cities. The currency...\n",
       "129459    Rome is the capital of Italy and of the Lazio ...\n",
       "66010     • Embassy is the office of the ambassador whil...\n",
       "271635    1 Prague: The Capital of the Czech Republic Pr...\n",
       "66005     Embassy and consulate refer to government repr...\n",
       "Name: doc_relevant, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8081      http://www.answers.com/Q/What_is_the_currency_...\n",
       "129459                   https://en.wikipedia.org/wiki/Rome\n",
       "66010     http://www.differencebetween.com/difference-be...\n",
       "271635    http://www.answers.com/Q/What_is_someone_from_...\n",
       "66005     http://www.differencebetween.net/business/diff...\n",
       "Name: url_relevant, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90682334, 0.9055239 , 0.9052953 , 0.90517753, 0.90047634]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8081, 129459,  66010, 271635,  66005])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tokens = torch.tensor([str_to_tokens(q, word_to_idx)])\n",
    "q_mask = (q_tokens != 0).float()\n",
    "\n",
    "q_encoding = model.query_encode(q_tokens, q_mask)\n",
    "q_projection = model.query_project(q_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_projection_np = q_projection.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8081      In Countries, States, and Cities. The currency...\n",
       "129459    Rome is the capital of Italy and of the Lazio ...\n",
       "66010     • Embassy is the office of the ambassador whil...\n",
       "271635    1 Prague: The Capital of the Czech Republic Pr...\n",
       "66005     Embassy and consulate refer to government repr...\n",
       "Name: doc_relevant, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = get_nearest_neighbors(q_projection_np)\n",
    "df.loc[indices]['doc_relevant']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the cosine similarity between the query and the document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_encoding = model.query_encode(query_tokens, query_mask)\n",
    "query_projection = model.query_project(query_encoding)\n",
    "\n",
    "cosine_similarities = F.cosine_similarity(query_projection, doc_projections, dim=1)\n",
    "cosine_similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
